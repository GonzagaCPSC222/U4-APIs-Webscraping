{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Webscraping\n",
    "What are our learning objectives for this lesson?\n",
    "* Learn the basics of HTML\n",
    "* Use the Beautiful Soup library to scrape data from simple, static webpages\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* None to report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s) \n",
    "Open APIFun and make a new Python module: bball_scraping.py. In this file, make a GET request for the HTML content at https://www.allmysportsteamssuck.com/ncaa-division-i-football-and-basketball-twitter-hashtags-and-handles/\n",
    "* This is just like making a JSON request to an API, except this URL does not route to an API but to a standard webpage :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today\n",
    "* Announcements\n",
    "    * MA9 notecard quiz at start of next class (Jupyter video + Markdown tutorial)\n",
    "    * DA4 due Monday 3/17 (first day back from break... get 'er done before you head out)\n",
    "        * Let's go over it, then questions\n",
    "        * Visit Alicia's office hours tonight, 5:30-6:30!\n",
    "    * Have a great API-filled weekend ðŸ˜\n",
    "* Today\n",
    "    * Web scraping example\n",
    "    * Start of VisualizationFun (See the Pandas Practice Problem in [U5/A Data Visualization notes](https://github.com/GonzagaCPSC222/U5-Visualizing-Data/blob/master/A%20Data%20Visualization.ipynb))\n",
    "    * IQ5 last ~15 mins of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping\n",
    "We can scrape data we are interested in from web pages. While there are several libraries to help you do this, today we will use [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/):\n",
    ">Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "\n",
    "### HTML Overview\n",
    "To perform webscraping, you do need some working knowledge of HTML. HTML is the standard markup language used to create web pages. HTML is characterized by tags, which are angle brackets < > used to \"label\" content. You have probably seen HTML before, maybe something like:\n",
    "\n",
    "```html\n",
    "<h1>This is a header</h1>\n",
    "```\n",
    "\n",
    "In the above example, the text \"This is a header\" is labeled as a first (top) level header. `<h1>` is the tag and `This is a header` is the content. Tag's can also have attributes that identify the tag and/or affect the content (image from: `https://miro.medium.com/v2/resize:fit:897/1*7wzysqclJLByh6qT1yqAnQ.png`):\n",
    "![](https://miro.medium.com/v2/resize:fit:897/1*7wzysqclJLByh6qT1yqAnQ.png)\n",
    "\n",
    "Basic webscraping typically involves knowledge of the following HTML tags (adapted from [Tutorial's Point](https://www.tutorialspoint.com/html/index.htm)):\n",
    "* Headings âˆ’ HTML provides six levels of headings from `<h1>` to `<h6>`, with `<h1>` being the highest (or most important) level and `<h6>` the lowest.\n",
    "* Paragraphs âˆ’ The `<p>` tag defines a paragraph.\n",
    "* Links âˆ’ The `<a>` tag defines a hyperlink, which is used to link from one page to another.\n",
    "* Lists âˆ’ HTML supports ordered, unordered, and definition lists.\n",
    "* Tables âˆ’ The `<table>` tag defines a table in HTML.\n",
    "* Divisions & Sections âˆ’ The `<div>` tag is a container unit that encapsulates other page elements and divides the HTML document into sections. \n",
    "    * HTML5 introduced semantic elements like `<section>`, `<article>`, `<header>`, `<footer>`, `<nav>`, etc., which serve a similar purpose but provide additional semantic information.\n",
    "\n",
    "There are lots of great resources online for learning HTML basics. Check out this [Codecademy tutorial](https://www.codecademy.com/learn/learn-html) or this [Tutorial's Point tutorial](https://www.tutorialspoint.com/html/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup\n",
    "The first thing we need to do, is make a \"soup\" object from some HTML. Assuming we have HTML content loaded into a string variable, `html_string`:\n",
    "`soup = BeautifulSoup(html_string)`\n",
    "\n",
    "By default, Beautiful Soup will use an HTML parser to parse the the HTML document into a complex tree of Python objects. You can specify other parsers as well (see the [documentation](https://beautiful-soup-4.readthedocs.io/en/latest/#making-the-soup)). Here are the most common Python objects Beautiful Soup parses the HTML into: \n",
    "* `Tag`\n",
    "* `NavigableString`\n",
    "* `BeautifulSoup` (e.g., the returned `soup` object)\n",
    "* `Comment`\n",
    "\n",
    "We will focus on `Tag` because HTML tags are the primary organizational object for HTML content and what we are looking for. Typically, we will use the `find()` (first tag occurrence of) and `find_all()` (all tag occurrences of) `BeautifulSoup` methods to search for strings in the text. For example: `soup.find_all('table')` to find all the `table` tags in the document. You can be more specific in your searching using the `attrs` keyword argument to search for HTML tags by their attribute values. For example: `soup.find_all(attrs={\"name\": \"email\"})` would return all the tags with attribute `name` set to `email`. This is useful to search for a specific `class` attribute value that web developers use to distinguish specific classes of tags. For example, here are three `div`s that represent rows in a table; however each div has a different class that is used for styling with CSS based on if the row represents a top 3 placement in a leaderboard (e.g., first place has a different color than second place:\n",
    "\n",
    "```html\n",
    "<div data-v-16526863=\"\" data-v-dba14418=\"\" data-v-6a34b37d=\"\" class=\"match-row match-row--top1\">\n",
    "<div data-v-16526863=\"\" data-v-dba14418=\"\" data-v-6a34b37d=\"\" class=\"match-row match-row--top2\">\n",
    "<div data-v-16526863=\"\" data-v-dba14418=\"\" data-v-6a34b37d=\"\" class=\"match-row match-row--top3\">\n",
    "<div data-v-16526863=\"\" data-v-dba14418=\"\" data-v-6a34b37d=\"\" class=\"match-row\">\n",
    "```\n",
    "\n",
    "Once you get a tag object, you can call the `get_text()` method to get the tag's content or the `get(key)` method to get the value of an attribute (identified by `key`) of the tag. See the Beautiful Soup documentation for more details and examples of how to search the `BeautifulSoup` object representing the HTML document tree: https://beautiful-soup-4.readthedocs.io/en/latest/#searching-the-tree\n",
    "\n",
    "With these basics (creating a `BeautifulSoup` object, searching it with `find()` and `find_all()` tag filters), you have enough tools in your webscraping toolbelt to get started searching for data you're looking for in static webpages. Open the wepbage in your browser and use your browser's developer tools to \"inspect\" or \"view page source.\" Find the content/data you want, then look to see the HTML tags it is nested in. Start searching for these identifying tags to parse what you want. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
